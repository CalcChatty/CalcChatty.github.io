{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CalcChatty/CalcChatty.github.io/blob/main/Start_Story.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "368686b4-f487-4dd4-aeff-37823976529d",
      "metadata": {
        "id": "368686b4-f487-4dd4-aeff-37823976529d"
      },
      "source": [
        "# Transformers version\n",
        "The `transformers` library will be used here for simplicity. The script will download the model into the colab virtual machine (which means it will be deleted and redownloaded). You will find that between waiting for models to download and the VERY slow speed of inference that this method is not something to be used regularly. Since this script will take care of all of the inference without any other knowledge or preparation, we will accept the slow speed for this example. The blocks that deal with models and inference only take about 2 minutes, so it's worth the wait and keep in mind that we will be implimenting a 10x speed boost in further iterations.\n",
        "\n",
        "## Installation\n",
        "Install transformers and accelerate with a quiet `-q` tag so we don't clutter too much with installer chatter we don't care about."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install transformers from source - only needed for versions <= v4.34\n",
        "%pip install git+https://github.com/huggingface/transformers.git -q\n",
        "%pip install accelerate -q"
      ],
      "metadata": {
        "id": "4ep8MF0OdrKO"
      },
      "id": "4ep8MF0OdrKO",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import pipeline, Conversation\n",
        "import json\n",
        "\n",
        "pipe = pipeline(\"conversational\", model=\"HuggingFaceH4/zephyr-7b-alpha\", torch_dtype=torch.bfloat16, device_map=\"auto\")"
      ],
      "metadata": {
        "id": "kMMc0QL2lP_i"
      },
      "id": "kMMc0QL2lP_i",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "story_data = {\n",
        "    \"concept_text\": \"Invoking the philosophical ideas of Albert Camus, generate two labelled paragraphs. A story concept that embodies and encapsulated their key themes. Provide: I. A captivating title. II. A brief paragraph summary of the story concept. III. A paragraph about the central themes that the story will address, reflecting Camus's perspectives on possible futures.\",\n",
        "    \"critique_text\": \"Considering possible critiques of the story concept and themes by Jean-Paul Sartre, and their philosophical viewpoints. Write a paragraph assessing how Sartre might challenge or enrich the narrative and a second paragraph discussing any potential conflicts or resonances between Camus's and Sartre's ideas.\",\n",
        "    \"update_text\": \"Update the title, story concept and themes considering Sartre's critique. Keep in mind I am writing from the male perspective. Do not mention any philosophy or philosophers in your response.\",\n",
        "    \"character_text\": \"Use the information in the Concept Summary and Themes to develop a Main Character. Create a three paragraph description for the protagonist in detail, ensuring that they align with the central themes and philosophies explored in the story. Give Physical, Backstory, and Personality description paragraphs.\",\n",
        "    \"setting_text\": \"Use this information in creating a single long paragraph about the setting and world-building elements. Give a detailed description of the world in which the story takes place, ensuring that it resonates with the central themes and philosophies explored in the narrative. Make sure not to develop the plot, just create the basic setting in one paragraph for now.\"\n",
        "}\n",
        "\n",
        "# Reference the dictionary in a way that creates user_prompts list\n",
        "prompts = [story_data[key] for key in story_data]\n",
        "user_prompts = [{\"role\": \"user\", \"content\": prompt} for prompt in prompts]\n",
        "user_prompts = [user_prompts]  # Wrap the list in another list to match the structure of chat completion\n",
        "start_text = [{\"role\": \"system\",\"content\":\"You are a writing assistant.\"}]\n",
        "\n",
        "def generate_and_display(msg):\n",
        "    conv = pipe(msg)\n",
        "    print(conv.messages[-1][\"content\"])\n",
        "    return conv\n"
      ],
      "metadata": {
        "id": "y4gg4oEb8mP2"
      },
      "id": "y4gg4oEb8mP2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The next 5 blocks will generate each of the story concept parts."
      ],
      "metadata": {
        "id": "KFHEwCy1jSXE"
      },
      "id": "KFHEwCy1jSXE"
    },
    {
      "cell_type": "code",
      "source": [
        "### Generate initial concept\n",
        "conversation = generate_and_display(start_text + [user_prompts[0][0]])\n",
        "conversation.add_message(user_prompts[0][1])"
      ],
      "metadata": {
        "id": "lIaCDdYmgTBu"
      },
      "id": "lIaCDdYmgTBu",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Generate critique of initial concept\n",
        "generate_and_display(conversation)\n",
        "conversation.add_message(user_prompts[0][2])"
      ],
      "metadata": {
        "id": "fxsn_zksguNr"
      },
      "id": "fxsn_zksguNr",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Generate update of initial concept\n",
        "generate_and_display(conversation)\n",
        "conversation.add_message(user_prompts[0][3])"
      ],
      "metadata": {
        "id": "KKUnyFEJGm0K"
      },
      "id": "KKUnyFEJGm0K",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Generate character bio\n",
        "generate_and_display(conversation)\n",
        "conversation.add_message(user_prompts[0][4])"
      ],
      "metadata": {
        "id": "68FgjKGqGyJQ"
      },
      "id": "68FgjKGqGyJQ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate setting\n",
        "generate_and_display(conversation)\n"
      ],
      "metadata": {
        "id": "E2SErbTuIo6Y"
      },
      "id": "E2SErbTuIo6Y",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "private_outputs": true,
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
